Metadata-Version: 2.4
Name: leadsearch
Version: 0.1.0
Summary: Hybrid (lexical + vector) multi-dataset search over large lead datasets (8M + 100k) with progress reporting.
Author: AutoGenerated
License: MIT
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: pandas>=2.2.0
Requires-Dist: tqdm>=4.66.0
Requires-Dist: sentence-transformers>=2.7.0
Requires-Dist: faiss-cpu>=1.7.4; platform_system != "Windows"
Requires-Dist: fastapi>=0.111.0
Requires-Dist: uvicorn>=0.30.0
Requires-Dist: openpyxl>=3.1.2
Requires-Dist: sqlite-utils>=3.36
Requires-Dist: numpy>=1.26.0
Requires-Dist: orjson>=3.10.0
Requires-Dist: python-dotenv>=1.0.1
Requires-Dist: hnswlib>=0.8.0
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: ruff; extra == "dev"

# Lead Search - Hybrid Dataset Search Engine

A high-performance hybrid search system for exploring 8M+ lead datasets with lexical (SQLite FTS5) + vector (FAISS) search capabilities and an interactive Streamlit web interface.

## ğŸš€ Quick Start

### Installation

```bash
# Clone/navigate to project
cd leadsearching

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install project and dependencies
pip install -e .

# Optional: Install Streamlit for web UI
pip install streamlit plotly
```

### Dataset Structure
This project works with two datasets:
- **8 Million Leads**: 17 CSV files (~100-115MB each) + 1 video
- **100k Leads**: 1 XLSX file (~11MB)

**Schema**: `username,name,bio,category,followerCount,followingCount,website,email,phone`

## ğŸ¯ Core Features

### 1. **Hybrid Search Architecture**
- **Lexical Search**: SQLite FTS5 for exact term matching
- **Vector Search**: FAISS with sentence transformers for semantic similarity
- **Score Fusion**: Reciprocal rank fusion for optimal result ranking

### 2. **Streamlit Web Interface**
```bash
streamlit run streamlit_app.py --server.port 8502
```

**Features:**
- ğŸ“Š **Dataset Overview**: Statistics, record counts, category breakdowns
- ğŸ“¥ **Data Ingestion**: Progress monitoring, batch processing, file pattern matching
- ğŸ” **Interactive Search**: Hybrid/lexical/vector modes, filtering, export
- ğŸ“ˆ **Results Analytics**: Category distribution, follower analysis, relevance scoring

### 3. **Command Line Interface**

#### Ingest Data
```bash
python -c "from leadsearch.cli import main; main()" ingest \
  --zip "8 MILLION LEADS-20250921T154416Z-1-001.zip" \
  --pattern "*.csv" \
  --dataset "8million" \
  --limit 5000  # Optional: for testing

python -c "from leadsearch.cli import main; main()" ingest \
  --zip "100k Sales Link 7 file-20250920T133656Z-1-001.zip" \
  --pattern "*.xlsx" \
  --dataset "100k" \
  --no-vectors  # Optional: skip embeddings for faster ingestion
```

#### Search Data
```bash
# Hybrid search (default)
python -c "from leadsearch.cli import main; main()" search \
  --query "startup founder tech email" \
  --limit 50

# Lexical only
python -c "from leadsearch.cli import main; main()" search \
  --query "marketing agency" \
  --mode lexical \
  --limit 100

# Vector/semantic only
python -c "from leadsearch.cli import main; main()" search \
  --query "business development" \
  --mode vector \
  --limit 25
```

#### Monitor Progress
```bash
python -c "from leadsearch.cli import main; main()" status
```

## ğŸ—ï¸ Architecture

### **Data Pipeline**
```
ZIP Archives â†’ Streaming Extraction â†’ CSV/XLSX Parsing â†’ 
Batch Processing (5k chunks) â†’ SQLite + FTS5 â†’ Vector Embeddings â†’ FAISS Index
```

### **Search Pipeline**
```
Query â†’ Lexical Search (SQLite FTS5) + Vector Search (FAISS) â†’ 
Score Fusion â†’ Ranking â†’ Results
```

### **Project Structure**
```
leadsearching/
â”œâ”€â”€ src/leadsearch/
â”‚   â”œâ”€â”€ config.py          # Settings management
â”‚   â”œâ”€â”€ progress.py        # JSON-based progress tracking
â”‚   â”œâ”€â”€ db.py             # SQLite schema & operations
â”‚   â”œâ”€â”€ embedding.py      # Sentence transformer model
â”‚   â”œâ”€â”€ vector_index.py   # FAISS/HNSW abstraction
â”‚   â”œâ”€â”€ ingest.py         # Streaming ingestion pipeline
â”‚   â”œâ”€â”€ search.py         # Hybrid search implementation
â”‚   â”œâ”€â”€ api.py            # FastAPI REST endpoints
â”‚   â””â”€â”€ cli.py            # Command-line interface
â”œâ”€â”€ streamlit_app.py      # Web interface
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ data/                 # Generated data directory
â”‚   â”œâ”€â”€ leads.db         # SQLite database
â”‚   â”œâ”€â”€ index/           # Vector index files
â”‚   â””â”€â”€ status.json      # Ingestion progress
â””â”€â”€ pyproject.toml       # Project configuration
```

## âš™ï¸ Configuration

Environment variables (optional):
```bash
export LEADSEARCH_DB_PATH="./data/leads.db"
export LEADSEARCH_INDEX_DIR="./data/index"
export LEADSEARCH_BATCH_SIZE=5000
export LEADSEARCH_MODEL_NAME="all-MiniLM-L6-v2"
export LEADSEARCH_FLUSH_EVERY=10
```

## ğŸ”§ Technical Details

### **Dependencies**
- **Data Processing**: pandas, tqdm, openpyxl
- **Search**: sqlite-utils (FTS5), faiss-cpu, sentence-transformers
- **API**: FastAPI, uvicorn
- **UI**: Streamlit, plotly
- **Storage**: SQLite, FAISS, numpy

### **Performance Optimizations**
- **Streaming Processing**: Handle large ZIP files without memory issues
- **Batch Ingestion**: 5k record chunks for optimal throughput
- **Progress Tracking**: JSON-based status with throttled writes
- **Vector Quantization**: fp16 storage option for memory efficiency
- **Index Persistence**: Save/load trained FAISS indexes

### **Search Modes**
- **`hybrid`** (default): Combines lexical + vector with RRF scoring
- **`lexical`**: SQLite FTS5 full-text search only
- **`vector`**: Semantic similarity via sentence transformers only

### **Quality Assurance**
- **Linting**: Ruff with modern Python type hints (PEP 585)
- **Code Style**: 100-character line limit, import sorting
- **Error Handling**: Comprehensive exception management
- **Type Safety**: Full type annotations throughout

## ğŸ“Š Usage Examples

### **Web Interface Workflow**
1. Launch: `streamlit run streamlit_app.py --server.port 8502`
2. Navigate to **Dataset Overview** for current statistics
3. Use **Ingestion** tab to process ZIP files with progress monitoring
4. **Search** tab for interactive queries with filtering and analytics
5. Export results as CSV for further analysis

### **Programmatic Usage**
```python
from leadsearch.config import get_settings
from leadsearch.db import connect
from leadsearch.search import hybrid_search

settings = get_settings()
conn = connect(settings.db_path)

results = hybrid_search(
    conn=conn,
    query="startup founder email",
    mode="hybrid",
    limit=100,
    min_score=0.2,
    filters={"category": "tech", "follower_min": 1000}
)

print(f"Found {len(results)} results")
for result in results[:5]:
    print(f"â€¢ {result['name']} ({result['username']}) - Score: {result['score']:.3f}")
```

## ğŸš€ Production Deployment

### **FastAPI REST Service**
```bash
python -c "from leadsearch.cli import main; main()" api --host 0.0.0.0 --port 8000
```

### **Docker Deployment** (Future)
```dockerfile
FROM python:3.11-slim
COPY . /app
WORKDIR /app
RUN pip install -e .
EXPOSE 8000
CMD ["python", "-c", "from leadsearch.cli import main; main()", "api"]
```

## ğŸ“ˆ Performance Metrics

### **Expected Throughput**
- **Ingestion**: ~500-1000 records/second (with vectors)
- **Search**: <100ms response time for hybrid queries
- **Storage**: ~2GB for 8M records (including vectors)

### **Memory Usage**
- **Ingestion**: ~200-500MB peak (streaming processing)
- **Search**: ~1-2GB (loaded embeddings + models)
- **Vectors**: ~800MB (all-MiniLM-L6-v2 embeddings for 8M records)

## ğŸ¤ Contributing

1. **Code Style**: Follows Ruff linting rules with modern Python patterns
2. **Type Safety**: Full type annotations required
3. **Testing**: Add unit tests for new functionality
4. **Documentation**: Update README and docstrings

## ğŸ“„ License

This project is developed for lead dataset exploration and search capabilities.

---

**ğŸ” Ready to explore 8M+ leads with hybrid AI-powered search!**

*Built with Python, SQLite FTS5, FAISS, and Streamlit*
